{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kangwonlee/stock-price-prediction-transformer/blob/main/stock_price_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import math\n",
        "import random\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout, GlobalAveragePooling1D\n",
        "\n"
      ],
      "metadata": {
        "id": "Ft4eOekeWIk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and prepare the dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "70-WRUq_XFi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import yfinance as yf\n",
        "except ModuleNotFoundError:\n",
        "  !pip install yfinance\n",
        "  import yfinance as yf\n",
        "\n",
        "logging.basicConfig(level=logging.DEBUG)\n",
        "\n"
      ],
      "metadata": {
        "id": "Wq_B5DBpYNGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(n=None):\n",
        "    time_step = 100\n",
        "    training_ratio = 0.67\n",
        "\n",
        "    start = \"2010-06-29\"\n",
        "    end = \"2024-10-04\"\n",
        "    period = '1d'\n",
        "\n",
        "    t_list = list(\n",
        "        set(\n",
        "          ['TSLA', 'AAPL', 'MSFT', 'AMZN', 'GOOGL',]\n",
        "          + ['VOO', 'QQQ', 'IWM', 'NVDA', 'META']\n",
        "          + ['XLY', 'XLK', 'XLU', 'XLB', 'XLI',]\n",
        "          + ['XLRE', 'XLF', 'XLP', 'XLE', 'XLC', 'XLV']\n",
        "        )\n",
        "    )\n",
        "\n",
        "    random.shuffle(t_list)\n",
        "\n",
        "    for ticker in t_list[:n]:\n",
        "      predict_price(\n",
        "          ticker,\n",
        "          time_step, training_ratio,\n",
        "          start, end, period\n",
        "      )\n",
        "\n"
      ],
      "metadata": {
        "id": "jOa4U5chXGIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_price(\n",
        "      ticker, time_step, training_ratio,\n",
        "      start=\"2010-06-29\", end=\"2022-03-25\", period='1d'\n",
        "    ):\n",
        "    logging.info(f'processing {ticker}')\n",
        "    scaler, data_scaled, dates = get_scaled_data(\n",
        "        ticker, start, end, period\n",
        "    )\n",
        "\n",
        "    \"\"\"\n",
        "    ## Parameters\n",
        "    \"\"\"\n",
        "\n",
        "    training_size = int(len(data_scaled) * training_ratio)\n",
        "    test_size = len(data_scaled) - training_size\n",
        "\n",
        "    # separate data into training and test\n",
        "    train_data = data_scaled[0:training_size,:]\n",
        "    test_data  = data_scaled[training_size:len(data_scaled),:]\n",
        "\n",
        "    X_train, y_train = create_dataset(train_data, time_step)\n",
        "    X_test, y_test = create_dataset(test_data, time_step)\n",
        "\n",
        "    \"\"\"\n",
        "    ## Reshape input for the model\n",
        "    \"\"\"\n",
        "\n",
        "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "    model = define_model(X_train)\n",
        "\n",
        "    \"\"\"## Model Summary\"\"\"\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    \"\"\"## Train the model\"\"\"\n",
        "\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=50, batch_size=64, verbose=1\n",
        "    )\n",
        "\n",
        "    \"\"\"\n",
        "    ## Make predictions\n",
        "    \"\"\"\n",
        "\n",
        "    # Make predictions\n",
        "    train_predict = model.predict(X_train)\n",
        "    test_predict = model.predict(X_test)\n",
        "\n",
        "    # Inverse transform predictions\n",
        "    train_predict = scaler.inverse_transform(train_predict)\n",
        "    test_predict = scaler.inverse_transform(test_predict)\n",
        "\n",
        "    # Evaluate the model (Optional: Calculate RMSE or other metrics)\n",
        "    train_rmse = math.sqrt(mean_squared_error(y_train, scaler.inverse_transform(train_predict.reshape(-1, 1))))\n",
        "    test_rmse = math.sqrt(mean_squared_error(y_test, scaler.inverse_transform(test_predict.reshape(-1, 1))))\n",
        "\n",
        "    print(f\"Train RMSE: {train_rmse}\")\n",
        "    print(f\"Test RMSE: {test_rmse}\")\n",
        "\n",
        "    visualize_predictions(\n",
        "        ticker, dates,\n",
        "        scaler, data_scaled,\n",
        "        time_step,\n",
        "        train_predict, test_predict\n",
        "    )\n",
        "    logging.info(f'finished {ticker}')\n",
        "\n"
      ],
      "metadata": {
        "id": "kExsu0E1XRDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nP5I5IrZSQB1"
      },
      "outputs": [],
      "source": [
        "def get_scaled_data(ticker, start=\"2010-06-29\", end=\"2022-03-25\", period='1d'):\n",
        "    df = yf.download(ticker, start=start, end=end, period=period)\n",
        "\n",
        "    data = df[['Close']].values\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "    dates = df.index.to_numpy()\n",
        "\n",
        "    return scaler, data_scaled, dates\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshape input for the model\n",
        "\n"
      ],
      "metadata": {
        "id": "zxSnJpz_XY5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(dataset, time_step=1):\n",
        "    dataX, dataY = [], []\n",
        "\n",
        "    for i in range(len(dataset) - time_step - 1):\n",
        "        a = dataset[i:(i + time_step), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + time_step, 0])\n",
        "\n",
        "    return np.array(dataX), np.array(dataY)\n"
      ],
      "metadata": {
        "id": "6cP_ykt3XfCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Block\n",
        "\n"
      ],
      "metadata": {
        "id": "Bh-Mux11W-j4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
        "    x = Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    x = LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = Dense(ff_dim, activation=\"relu\")(x)\n",
        "    x = Dropout(dropout)(x)\n",
        "    x = Dense(inputs.shape[-1])(x)\n",
        "    return x + res\n"
      ],
      "metadata": {
        "id": "_phr1ROFW-Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition\n",
        "\n"
      ],
      "metadata": {
        "id": "qO3jIGQwW6Rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model(X_train):\n",
        "\n",
        "    \"\"\"\n",
        "    ## Model Definition\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
        "    x = transformer_encoder(inputs, head_size=256, num_heads=4, ff_dim=4, dropout=0.1)\n",
        "    x = GlobalAveragePooling1D(data_format='channels_first')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = Dense(20, activation=\"relu\")(x)\n",
        "    outputs = Dense(1, activation=\"linear\")(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "EBQ-hyx2W53b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_predictions(ticker, dates, scaler, data_scaled, time_step, train_predict, test_predict):\n",
        "    \"\"\"\n",
        "    ## Plotting the results\n",
        "    \"\"\"\n",
        "\n",
        "    # Adjust the time_step offset for plotting\n",
        "    trainPredictPlot = np.empty_like(data_scaled)\n",
        "    trainPredictPlot[:, :] = np.nan\n",
        "    trainPredictPlot[time_step:len(train_predict)+time_step, :] = train_predict\n",
        "\n",
        "    # Shift test predictions for plotting\n",
        "    testPredictPlot = np.empty_like(data_scaled)\n",
        "    testPredictPlot[:, :] = np.nan\n",
        "    testPredictPlot[len(train_predict)+(time_step*2)+1:len(data_scaled)-1, :] = test_predict\n",
        "\n",
        "    # Plot baseline and predictions\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.semilogy(dates, scaler.inverse_transform(data_scaled), label='Actual Stock Price')\n",
        "    plt.semilogy(dates, trainPredictPlot, label='Train Predict')\n",
        "    plt.semilogy(dates, testPredictPlot, label='Test Predict')\n",
        "    plt.title(f'Stock Price Prediction using Transformer {ticker}')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Stock Price')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(f'{ticker}_result.png', dpi=300)\n"
      ],
      "metadata": {
        "id": "qmrw1pJLWzYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "main()\n",
        "\n"
      ],
      "metadata": {
        "id": "oNI0RRI2xOYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "\n",
        "result_folder = pathlib.Path('results')\n",
        "result_folder.mkdir(exist_ok=True)\n",
        "\n",
        "png_files = pathlib.Path().glob('*.png')\n",
        "for png_file in png_files:\n",
        "    png_file.rename(result_folder / png_file.name)\n",
        "\n",
        "!zip -r results.zip results\n",
        "\n"
      ],
      "metadata": {
        "id": "PML_S1GtxoYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4oTvRRgD9OY3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}