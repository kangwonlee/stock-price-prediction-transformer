{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout, GlobalAveragePooling1D\n",
        "\n"
      ],
      "metadata": {
        "id": "Ft4eOekeWIk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and prepare the dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "70-WRUq_XFi9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uc_PqqcaZdcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "\n",
        "ticker = 'TSLA'\n",
        "data_ohlc = yf.download(ticker, start=\"2010-06-29\", end=\"2022-03-24\", period='1d')\n",
        "data_close = data_ohlc['Close'].tolist()\n",
        "\n"
      ],
      "metadata": {
        "id": "Wq_B5DBpYNGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_path = 'TSLA.csv'  # Make sure to have your dataset ready\n",
        "df = pd.read_csv(file_path)\n",
        "data = df[['Close']].values\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n"
      ],
      "metadata": {
        "id": "jOa4U5chXGIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(dataset, time_step=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset) - time_step - 1):\n",
        "        a = dataset[i:(i + time_step), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + time_step, 0])\n",
        "    return np.array(dataX), np.array(dataY)\n",
        "\n"
      ],
      "metadata": {
        "id": "kExsu0E1XRDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters\n",
        "\n"
      ],
      "metadata": {
        "id": "QRVGuNsgXUad"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nP5I5IrZSQB1"
      },
      "outputs": [],
      "source": [
        "time_step = 100\n",
        "training_size = int(len(data_scaled) * 0.67)\n",
        "test_size = len(data_scaled) - training_size\n",
        "train_data, test_data = data_scaled[0:training_size,:], data_scaled[training_size:len(data_scaled),:]\n",
        "\n",
        "X_train, y_train = create_dataset(train_data, time_step)\n",
        "X_test, y_test = create_dataset(test_data, time_step)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshape input for the model\n",
        "\n"
      ],
      "metadata": {
        "id": "zxSnJpz_XY5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "6cP_ykt3XfCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Block\n",
        "\n"
      ],
      "metadata": {
        "id": "Bh-Mux11W-j4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
        "    x = Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    x = LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = Dense(ff_dim, activation=\"relu\")(x)\n",
        "    x = Dropout(dropout)(x)\n",
        "    x = Dense(inputs.shape[-1])(x)\n",
        "    return x + res\n"
      ],
      "metadata": {
        "id": "_phr1ROFW-Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition\n",
        "\n"
      ],
      "metadata": {
        "id": "qO3jIGQwW6Rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
        "x = transformer_encoder(inputs, head_size=256, num_heads=4, ff_dim=4, dropout=0.1)\n",
        "x = GlobalAveragePooling1D(data_format='channels_first')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(20, activation=\"relu\")(x)\n",
        "outputs = Dense(1, activation=\"linear\")(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
        "\n"
      ],
      "metadata": {
        "id": "EBQ-hyx2W53b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Summary"
      ],
      "metadata": {
        "id": "aZmwM7wTWzrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "qmrw1pJLWzYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "yT2MCLOGWuoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=50, batch_size=64, verbose=1\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "nLg4gT9GWoTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make predictions\n",
        "\n"
      ],
      "metadata": {
        "id": "86vqEJTnWiFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "train_predict = model.predict(X_train)\n",
        "test_predict = model.predict(X_test)\n",
        "\n",
        "# Inverse transform predictions\n",
        "train_predict = scaler.inverse_transform(train_predict)\n",
        "test_predict = scaler.inverse_transform(test_predict)\n",
        "\n",
        "# Evaluate the model (Optional: Calculate RMSE or other metrics)\n",
        "train_rmse = math.sqrt(mean_squared_error(y_train, scaler.inverse_transform(train_predict.reshape(-1, 1))))\n",
        "test_rmse = math.sqrt(mean_squared_error(y_test, scaler.inverse_transform(test_predict.reshape(-1, 1))))\n",
        "\n",
        "print(f\"Train RMSE: {train_rmse}\")\n",
        "print(f\"Test RMSE: {test_rmse}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "kDtvXcVZWfIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the results\n",
        "\n"
      ],
      "metadata": {
        "id": "jbehmQvCWaC-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fimUlsZSc6G"
      },
      "outputs": [],
      "source": [
        "# Adjust the time_step offset for plotting\n",
        "trainPredictPlot = np.empty_like(data_scaled)\n",
        "trainPredictPlot[:, :] = np.nan\n",
        "trainPredictPlot[time_step:len(train_predict)+time_step, :] = train_predict\n",
        "\n",
        "# Shift test predictions for plotting\n",
        "testPredictPlot = np.empty_like(data_scaled)\n",
        "testPredictPlot[:, :] = np.nan\n",
        "testPredictPlot[len(train_predict)+(time_step*2)+1:len(data_scaled)-1, :] = test_predict\n",
        "\n",
        "# Plot baseline and predictions\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.semilogy(scaler.inverse_transform(data_scaled), label='Actual Stock Price')\n",
        "plt.semilogy(trainPredictPlot, label='Train Predict')\n",
        "plt.semilogy(testPredictPlot, label='Test Predict')\n",
        "plt.title('Stock Price Prediction using Transformer')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('stock_price_prediction.png', dpi=300)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}